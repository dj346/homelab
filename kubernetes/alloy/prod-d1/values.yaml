
alloy:
  clustering:
    enabled: false
    name: ""
    portName: http

  configMap:
    create: true
    content: |-
      prometheus.remote_write "mimir" {
        endpoint {
          url     = "http://mimir-nginx.mimir.svc.cluster.local:80/api/v1/push"
          url     = "http://mimir-gateway.mimir.svc.cluster.local:80/api/v1/push"
          
          headers = {
            "X-Scope-OrgID" = "anonymous",
          }
        }
      }

      prometheus.exporter.self "self_metrics" {}

      prometheus.scrape "self_scrape" {
        targets    = prometheus.exporter.self.self_metrics.targets
        forward_to = [prometheus.remote_write.mimir.receiver]
      }

      discovery.kubernetes "mimir_pods" {
        role = "pod"

        namespaces {
          own_namespace = false
          names         = ["mimir"]
        }

        selectors {
          role  = "pod"
          label = "app.kubernetes.io/name=mimir"
        }
      }

      discovery.relabel "mimir_pods_8080" {
        targets = discovery.kubernetes.mimir_pods.targets

        rule {
          action        = "keep"
          source_labels = ["__meta_kubernetes_pod_container_port_number"]
          regex         = "8080"
        }
      }

      prometheus.scrape "mimir_pods" {
        targets    = discovery.relabel.mimir_pods_8080.output
        forward_to = [prometheus.remote_write.mimir.receiver]
      }


  storagePath: /tmp/alloy

  listenAddr: 0.0.0.0
  listenPort: 12345
  listenScheme: HTTP

  # Telemetry configuration
  enableReporting: true

  mounts:
    varlog: false
    dockercontainers: false
    extra: []

  resources: {}

configReloader:
  enabled: true

  resources:
    requests:
      cpu: "10m"
      memory: "50Mi"

controller:
  replicas: 1

  extraAnnotations: {}
  podAnnotations: {}
  podLabels: {}

  # -- PodDisruptionBudget configuration.
  podDisruptionBudget:
    # -- Whether to create a PodDisruptionBudget for the controller.
    enabled: false
    # -- Minimum number of pods that must be available during a disruption.
    # Note: Only one of minAvailable or maxUnavailable should be set.
    minAvailable: null
    # -- Maximum number of pods that can be unavailable during a disruption.
    # Note: Only one of minAvailable or maxUnavailable should be set.
    maxUnavailable: null

  # -- Whether to enable automatic deletion of stale PVCs due to a scale down operation, when controller.type is 'statefulset'.
  enableStatefulSetAutoDeletePVC: false

  autoscaling:
    horizontal:
      enabled: false
      minReplicas: 1
      maxReplicas: 5
      targetCPUUtilizationPercentage: 0
      targetMemoryUtilizationPercentage: 80

      scaleDown:
        policies: []
        selectPolicy: Max
        stabilizationWindowSeconds: 300

      scaleUp:
        policies: []
        selectPolicy: Max
        stabilizationWindowSeconds: 0
    vertical:
      enabled: false
      recommenders: []
      resourcePolicy:
        containerPolicies:
        - containerName: alloy
          controlledResources:
          - cpu
          - memory
          controlledValues: "RequestsAndLimits"
          maxAllowed: {}
          minAllowed: {}

service:
  enabled: true
  type: ClusterIP
  nodePort: 31128
  clusterIP: ''
  internalTrafficPolicy: Cluster
  annotations: {}

serviceMonitor:
  enabled: false
  additionalLabels: {}
  interval: ""
  metricRelabelings: []
  tlsConfig: {}
  relabelings: []

ingress:
  enabled: false
  annotations: {}
  labels: {}
  path: /
  faroPort: 12347
  pathType: Prefix
  hosts:
    - chart-example.local
  extraPaths: []

  tls: []